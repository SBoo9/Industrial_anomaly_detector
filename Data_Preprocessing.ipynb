{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e113d1-a798-4152-8c02-a679f04b4da9",
   "metadata": {},
   "source": [
    "## Step 1: Load and Inspect the Dataset\n",
    "\n",
    "### Loading the Data\n",
    "We load the synthetic IoT sensor data from a CSV file. The `timestamp` column is parsed as a `datetime` object and set as the index to facilitate time-based operations.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv('synthetic_iot_sensor_data.csv', parse_dates=['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2b540a-f6f7-4682-91af-d0b16a727fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     temperature  vibration    pressure   humidity  failure  \\\n",
      "timestamp                                                                     \n",
      "2024-12-01 00:00:00    27.746529   1.291776  162.724539  49.082652        0   \n",
      "2024-12-01 00:01:00    28.762782   1.163971  143.952310  53.087117        0   \n",
      "2024-12-01 00:02:00    27.959954   1.163477  159.641210  47.865008        0   \n",
      "2024-12-01 00:03:00    33.445726   1.262017  161.557163  51.507817        0   \n",
      "2024-12-01 00:04:00    30.700783   0.941095  162.739058  61.794441        0   \n",
      "\n",
      "                     machine_id  \n",
      "timestamp                        \n",
      "2024-12-01 00:00:00           1  \n",
      "2024-12-01 00:01:00           1  \n",
      "2024-12-01 00:02:00           1  \n",
      "2024-12-01 00:03:00           1  \n",
      "2024-12-01 00:04:00           1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file (change the filename if needed)\n",
    "df = pd.read_csv('synthetic_iot_sensor_data.csv', parse_dates=['timestamp'])\n",
    "\n",
    "# Set timestamp as the index to facilitate time-based operations\n",
    "df.set_index('timestamp', inplace=True)\n",
    "\n",
    "# View the first few rows of the dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe774b9b-c8f9-42d0-9c46-80623ad04269",
   "metadata": {},
   "source": [
    "## Checking for Missing Values\n",
    "We check for missing values in the dataset and handle them using forward fill (ffill) and backward fill (bfill) methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d535706-4d33-48a3-a026-03adfdb7dc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "temperature    0\n",
      "vibration      0\n",
      "pressure       0\n",
      "humidity       0\n",
      "failure        0\n",
      "machine_id     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sb075216\\AppData\\Local\\Temp\\ipykernel_13912\\3736700359.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)  # Forward fill\n",
      "C:\\Users\\sb075216\\AppData\\Local\\Temp\\ipykernel_13912\\3736700359.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)  # Backward fill\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_counts = df.isnull().sum()\n",
    "print(f\"Missing Values:\\n{missing_counts}\")\n",
    "\n",
    "# Fill missing values using forward fill, backward fill, or interpolation\n",
    "df.fillna(method='ffill', inplace=True)  # Forward fill\n",
    "df.fillna(method='bfill', inplace=True)  # Backward fill\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92352f-170b-4d0e-94ad-db56cea94323",
   "metadata": {},
   "source": [
    "## Step 2: Outlier Detection and Capping\n",
    "Detecting and Capping Outliers\n",
    "We identify outliers in sensor data using the Interquartile Range (IQR) method and cap them within a valid range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "741690e5-e443-47a4-a0d6-d47a257fa185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         temperature      vibration       pressure       humidity  \\\n",
      "count  432000.000000  432000.000000  432000.000000  432000.000000   \n",
      "mean       30.193101       1.020732     150.121604      50.023433   \n",
      "std         7.623520       0.765009      36.747368      14.707954   \n",
      "min        12.247470      -0.846734      63.612176      13.235434   \n",
      "25%        23.307757       0.328889     116.454736      36.451290   \n",
      "50%        30.124453       1.012455     150.109059      49.967662   \n",
      "75%        36.875796       1.688356     183.944987      63.551031   \n",
      "max        57.227855       3.727556     235.730156      84.902346   \n",
      "\n",
      "             failure     machine_id  \n",
      "count  432000.000000  432000.000000  \n",
      "mean        0.006944       5.500000  \n",
      "std         0.083044       2.872285  \n",
      "min         0.000000       1.000000  \n",
      "25%         0.000000       3.000000  \n",
      "50%         0.000000       5.500000  \n",
      "75%         0.000000       8.000000  \n",
      "max         1.000000      10.000000  \n"
     ]
    }
   ],
   "source": [
    "# Detect and cap outliers using IQR\n",
    "def cap_outliers(series, threshold=1.5):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "    return np.clip(series, lower_bound, upper_bound)\n",
    "\n",
    "# Apply capping to sensor columns\n",
    "for col in ['temperature', 'vibration', 'pressure', 'humidity']:\n",
    "    df[col] = cap_outliers(df[col])\n",
    "\n",
    "# View summary statistics to ensure outliers are capped\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff592a3f-4c89-4d85-9e4b-894e085675a7",
   "metadata": {},
   "source": [
    "## Step 3: Data Resampling\n",
    "Resampling to Hourly Data\n",
    "The data is resampled to hourly intervals, and the mean of each sensor's readings is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d24c669-024d-4b01-8e24-5dc008e6df19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     temperature  vibration    pressure   humidity  failure  \\\n",
      "timestamp                                                                     \n",
      "2024-12-01 00:00:00    35.194576   1.543561  174.481228  60.699344      0.0   \n",
      "2024-12-01 01:00:00    38.988500   1.956669  194.782088  68.449871      0.0   \n",
      "2024-12-01 02:00:00    31.835665   1.208833  156.979400  52.262330      0.0   \n",
      "2024-12-01 03:00:00    21.945653   0.161972  110.353798  33.953453      0.0   \n",
      "2024-12-01 04:00:00    22.696499   0.274998  115.117618  35.854095      0.0   \n",
      "\n",
      "                     machine_id  \n",
      "timestamp                        \n",
      "2024-12-01 00:00:00         5.5  \n",
      "2024-12-01 01:00:00         5.5  \n",
      "2024-12-01 02:00:00         5.5  \n",
      "2024-12-01 03:00:00         5.5  \n",
      "2024-12-01 04:00:00         5.5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sb075216\\AppData\\Local\\Temp\\ipykernel_13912\\2803440340.py:2: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_resampled = df.resample('H').mean()  # Resample hourly and compute mean\n"
     ]
    }
   ],
   "source": [
    "# Resample to hourly data (you can also use 'D' for daily, '15T' for 15-minute intervals)\n",
    "df_resampled = df.resample('H').mean()  # Resample hourly and compute mean\n",
    "print(df_resampled.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf9a43-d975-4ffe-8ad3-4ec1a18378f3",
   "metadata": {},
   "source": [
    "## Step 4: Feature Engineering\n",
    "Creating Lag Features\n",
    "Lag features are added for the past 1 to 3 time points for each sensor column, capturing temporal dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d1ace55-e49d-40b3-b928-d8e3c0158187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features for the past 3 time points\n",
    "for col in ['temperature', 'vibration', 'pressure', 'humidity']:\n",
    "    for lag in range(1, 4):  # Lags 1, 2, and 3\n",
    "        df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bab90b-1eb8-4076-9efa-ceec8eaa4b79",
   "metadata": {},
   "source": [
    "Adding Rolling Statistics\n",
    "Rolling statistics such as mean, standard deviation, minimum, maximum, kurtosis, and skewness are calculated over a 60-minute window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fe27ad-d8d6-496d-ad6d-7aa42fecb116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling windows for past 60 timestamps (since this is minute-based, 60 = 1 hour)\n",
    "for col in ['temperature', 'vibration', 'pressure', 'humidity']:\n",
    "    df[f'{col}_rolling_mean'] = df[col].rolling(window=60).mean()\n",
    "    df[f'{col}_rolling_std'] = df[col].rolling(window=60).std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e126c27-a2d0-4fbe-b7b1-15dff81d7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute rolling min, max, kurtosis, skewness\n",
    "for col in ['temperature', 'vibration', 'pressure', 'humidity']:\n",
    "    df[f'{col}_rolling_min'] = df[col].rolling(window=60).min()\n",
    "    df[f'{col}_rolling_max'] = df[col].rolling(window=60).max()\n",
    "    df[f'{col}_rolling_kurtosis'] = df[col].rolling(window=60).kurt()\n",
    "    df[f'{col}_rolling_skew'] = df[col].rolling(window=60).skew()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea553876-0180-4ee0-b52a-8a6f2b5375e9",
   "metadata": {},
   "source": [
    "Adding Cyclic Features\n",
    "Cyclic features are created to capture time-of-day (hour) and day-of-week (day_of_week) patterns. Sine and cosine transformations are applied for encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f067d611-b133-4cd9-b91d-2e35a4db984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cyclic features for time-of-day (hour) and day-of-week\n",
    "df['hour'] = df.index.hour\n",
    "df['day_of_week'] = df.index.dayofweek\n",
    "\n",
    "# Sin/Cos transformations for cyclic encoding\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['dayofweek_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['dayofweek_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd30567-741a-40bb-876e-71fb4f4d0801",
   "metadata": {},
   "source": [
    "## Step 5: Final Preprocessing and Export\n",
    "Handling NaN Values\n",
    "NaN values introduced during lag and rolling calculations are dropped to ensure data consistency.\n",
    "Exporting the Processed Data\n",
    "The preprocessed dataset is saved as a new CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "929c2e7e-03cb-4bcf-9045-bc8218f629d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values (introduced by lags, rolling, etc.)\n",
    "df = df.dropna()\n",
    "\n",
    "# Export the preprocessed dataset\n",
    "df.to_csv('processed_iot_sensor_data.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9d692-5719-421e-9019-016ef75b367f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
